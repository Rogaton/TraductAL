# TraductAL - an offline Neural Machine Translation with NLLB-200

A completely offline, privacy-focused neural machine translation system powered by Meta's NLLB-200 models. All translations happen locally on your machine with no data sent to external servers.

## âš ï¸ Development Status & Disclaimer

**USE AT YOUR OWN RISK** - This system is currently in active development and not ready for production use.

### Known Limitations:
- **Incomplete translations**: Some words or text segments may be missing from output
- **Quality varies**: Translation accuracy depends on language pair and text complexity  
- **No quality guarantees**: Results may not be suitable for professional or critical use
- **Model limitations**: Base NLLB-200 models may require fine-tuning for specific domains

### Recommended Use:
- âœ… Development and testing purposes
- âœ… Personal experimentation with offline translation
- âœ… Privacy-focused translation where perfect accuracy isn't critical
- âŒ Production systems requiring reliable translations
- âŒ Professional document translation without human review
- âŒ Critical communications or legal documents

## ğŸ”’ Privacy & Security
- **100% Offline**: No internet connection required after setup
- **Zero Data Leakage**: All processing happens locally
- **Professional Grade**: Suitable for confidential document translation
- **No Logging**: No translation history stored externally

## ğŸŒ Language Support

NLLB-200 supports 200+ languages with excellent quality for:
- **European languages**: English, French, German, Spanish, Italian, Portuguese, Russian
- **Asian languages**: Chinese, Japanese, Korean, Hindi, Arabic, Turkish
- **Many more**: Including low-resource languages with good quality

## ğŸš€ Quick Start

### Installation
```bash
# Clone the repository
git clone <repository-url>
cd TraductAL

# Install dependencies
pip install -r requirements.txt

# Download NLLB models
python download_nllb_200.py
```

### Basic Usage
```bash
# Simple translation
./translate_enhanced.sh en fr "Hello, how are you?"

# Interactive mode
./translate_enhanced.sh interactive en fr

# List available languages
./translate_enhanced.sh list-languages

# System health check
./translate_enhanced.sh check
```

### Python API
```python
from nllb_translator import EnhancedOfflineTranslator

translator = EnhancedOfflineTranslator()
result = translator.translate("Hello world", "en", "fr")
print(result["translation"])  # "Bonjour Ã¤ tous"
```

## ğŸ“Š Model Options

### NLLB-200-1.3B (Recommended)
- **Size**: ~2.6GB
- **Speed**: 0.5-1.0 seconds per sentence
- **Memory**: ~3GB RAM
- **Quality**: Very High

### NLLB-200-3.3B (Maximum Quality)
- **Size**: ~6.6GB  
- **Speed**: 1.0-2.0 seconds per sentence
- **Memory**: ~7GB RAM
- **Quality**: Excellent

## ğŸ› ï¸ System Requirements

- **Python**: 3.8+
- **RAM**: 4GB minimum (8GB recommended)
- **Storage**: 3-7GB for models
- **OS**: Linux, macOS, Windows

## ğŸ“ Project Structure

```
TraductAL/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ LICENSE                   # MIT License
â”œâ”€â”€ nllb_translator.py        # Main translator class
â”œâ”€â”€ translate_enhanced.sh     # Command-line interface
â”œâ”€â”€ download_nllb_200.py      # Model downloader
â”œâ”€â”€ migrate_to_nllb.py        # Migration utility
â”œâ”€â”€ NLLB_UPGRADE_GUIDE.md     # Detailed upgrade guide
â”œâ”€â”€ QUICK_REFERENCE.md        # Command reference
â”œâ”€â”€ MIGRATION_SUMMARY.md      # Migration documentation
â””â”€â”€ models/
    â””â”€â”€ deployed_models/
        â”œâ”€â”€ nllb_200_1.3b/   # NLLB 1.3B model files
        â””â”€â”€ nllb_200_3.3b/   # NLLB 3.3B model files
```

## ğŸ”§ Advanced Usage

### Batch Translation
```bash
# Translate multiple lines
echo -e "Hello\nGoodbye\nThank you" | ./translate_enhanced.sh en fr

# Translate from file
./translate_enhanced.sh en fr "$(cat input.txt)"
```

### Model Selection
```python
# Use specific model
translator = EnhancedOfflineTranslator()
result = translator.translate("Hello", "en", "fr", model="nllb_200_3_3b")
```

### Performance Monitoring
```python
result = translator.translate("Hello world", "en", "fr")
print(f"Translation time: {result['time']:.2f}s")
print(f"Model used: {result['method']}")
```

## ğŸŒŸ Key Features

- **High-quality translations** with NLLB-200 models
- **200+ language support** including low-resource languages
- **Bidirectional translation** for all language pairs
- **Automatic model selection** based on availability
- **Performance monitoring** and optimization
- **Professional-grade privacy** with offline operation
- **Easy integration** with Python API and shell commands

## ğŸ”„ Migration from Other Systems

If you're migrating from MT5 or other translation systems:

```bash
# Run the migration script
python migrate_to_nllb.py

# Follow the upgrade guide
cat NLLB_UPGRADE_GUIDE.md
```

## ğŸ“– Documentation

- **[NLLB_UPGRADE_GUIDE.md](NLLB_UPGRADE_GUIDE.md)**: Detailed upgrade instructions
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)**: Command reference sheet
- **[MIGRATION_SUMMARY.md](MIGRATION_SUMMARY.md)**: Migration documentation
- **[LICENSE_INFO.md](LICENSE_INFO.md)**: Licensing information

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Meta AI** for the NLLB-200 models
- **Hugging Face** for the Transformers library
- **PyTorch** team for the deep learning framework

---

**Ready to translate?** Run `python download_nllb_200.py` to get started!
